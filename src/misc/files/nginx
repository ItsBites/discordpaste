worker_processes 1;
error_log stderr notice;

events {
    worker_connections 1024;
}

http {

  types_hash_max_size 2048;

  upstream cabot_app {
    server app:5000 max_fails=3 fail_timeout=3s;
  }

  server {
    listen 8080;

    location / {
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header Host $http_host;
      proxy_redirect off;
      proxy_pass http://cabot_app;
     }

    location /static/ {
      include       /etc/nginx/mime.types;
      default_type  application/octet-stream;
      root /cabot/;
    }
  }
}

worker_processes  1;

events {
  worker_connections  1024;
}

http {
  include       mime.types;
  default_type  application/octet-stream;

  sendfile        on;
  keepalive_timeout  65;

  # Use the local dnsmasq server to resolve. By doing this, we can handle app
  # servers bound to IPv4 or IPv6 versions of "localhost", whereas binding to
  # proxying to 127.0.0.1 wouldn't work for (for instance) newer versions of
  # Rails.
  resolver 127.0.0.1;

  # This map allows us to refer to $static_content_root in our location blocks,
  # and get an appropriate root back based on the "app" portion of the hostname
  # we connect to. The named matches ("app" and "subdir") below will also set
  # variables that are available to us in the path we return. A reasonable
  # convention (used by Rails, for instance) is to have a /public directory
  # inside the project's root, so this is what we are defaulting to here.
  map $host $static_content_root {
    hostnames; # Allows us to use wildcard matching, e.g., *.local.devel

    # If you want to put some kind of static index.html in this location, it'll
    # display if you access the root of a project that doesn't have a match.
    default <MY_PROJECT_ROOT>;

    # For typical standalone apps living in your project directory
    # *.myapp.local.devel -> <MY_PROJECT_ROOT>/myapp/public
    ~^([^\.]+\.)*(?<app>[^\.]+)\.local\.devel$
      <MY_PROJECT_ROOT>/$app/public;

    # For apps that are part of a group of some kind (e.g., SOA apps), you can
    # place all apps inside of a subdirectory, and use the subdirectory name in
    # place of "local".
    # *.sub.myapp.devel -> <MY_PROJECT_ROOT>/myapp/sub/public
    ~^([^\.]+\.)*(?<app>[^\.]+)\.(?<subdir>[^\.]+)\.devel$
      <MY_PROJECT_ROOT>/$subdir/$app/public;
  }

  # In order to proxy to the proper app, we include a file with maps for devel
  # and staging ports for specific apps. They default to 3000 and 4000,
  # respectively, so you can always use apps that don't need to run together
  # by just starting them up on that port. That keeps the need to generate/edit
  # the proxy_ports.conf minimal.
  include proxy_ports.conf;

  # Handle HTTP requests to *.devel
  server {
    listen       127.0.0.1:8080;
    server_name  *.devel;

    location / {
      root   $static_content_root; # Using the map we defined earlier
      try_files $uri $uri/index.html @devel;
    }

    location @devel {
      proxy_set_header  Upgrade           $http_upgrade;
      proxy_set_header  Connection        "upgrade";
      proxy_http_version 1.1;
      proxy_set_header  X-Real-IP         $remote_addr;
      proxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header  Host              $http_host;
      proxy_redirect    off;
      proxy_pass        http://localhost:$devel_proxy_port;
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
      root   html;
    }
  }

  # Handle HTTPS requests to *.devel
  server {
    listen       127.0.0.1:8443;
    server_name  *.devel;

    ssl on;
    ssl_certificate     /usr/local/etc/nginx/ssl/local.devel.pem;
    ssl_certificate_key /usr/local/etc/nginx/ssl/local.devel.key;
    ssl_session_timeout 5m;

    location / {
      root   $static_content_root; # Using the map we defined earlier
      try_files $uri $uri/index.html @devel;
    }

    # Note that this block is slightly different than the non-HTTPS one. If we
    # don't set X-Forwarded-Proto, then if our app tries to force SSL, it will
    # end up in a redirect loop.
    location @devel {
      proxy_set_header  Upgrade           $http_upgrade;
      proxy_set_header  Connection        "upgrade";
      proxy_http_version 1.1;
      proxy_set_header  X-Real-IP         $remote_addr;
      proxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header  X-Forwarded-Proto $scheme;
      proxy_set_header  Host              $http_host;
      proxy_redirect    off;
      proxy_pass        http://localhost:$devel_proxy_port;
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
      root   html;
    }
  }

  # Handle HTTP requests to *.staging. We can't define the server_name that way,
  # though, because we want it to capture the "app" portion of the URL in $app.
  # We need this so our $staging_proxy_port map will work.
  server {
    listen       127.0.0.1:8080;
    server_name  ~^([^\.]+\.)*(?<app>[^\.]+)\.[^\.]+.staging$;

    location / {
      proxy_set_header  Upgrade           $http_upgrade;
      proxy_set_header  Connection        "upgrade";
      proxy_http_version 1.1;
      proxy_set_header  X-Real-IP         $remote_addr;
      proxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header  Host              $http_host;
      proxy_redirect    off;
      proxy_pass        http://192.168.59.103:$staging_proxy_port;
    }
  }

  # Handle HTTPS requests to *.staging. Again, we can't define the server_name
  # that way.
  server {
    listen       127.0.0.1:8443;
    server_name  ~^([^\.]+\.)*(?<app>[^\.]+)\.[^\.]+.staging$;

    ssl on;
    ssl_certificate     /usr/local/etc/nginx/ssl/local.devel.pem;
    ssl_certificate_key /usr/local/etc/nginx/ssl/local.devel.key;
    ssl_session_timeout 5m;

    location / {
      proxy_set_header  Upgrade           $http_upgrade;
      proxy_set_header  Connection        "upgrade";
      proxy_http_version 1.1;
      proxy_set_header  X-Real-IP         $remote_addr;
      proxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;
      proxy_set_header  X-Forwarded-Proto $scheme;
      proxy_set_header  Host              $http_host;
      proxy_redirect    off;
      proxy_pass        http://192.168.59.103:$staging_proxy_port;
    }
  }

}
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    # include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;

}

# nginx Configuration File
# http://wiki.nginx.org/Configuration
#
# Using the nginx.conf here as a base:
#     https://github.com/h5bp/server-configs-nginx
# Also using suggestions from "Battle ready Nginx" article:
#     http://blog.zachorr.com/nginx-setup/

# Run as a less privileged user for security reasons.
user www-data;

# How many worker threads to run;
# "auto" sets it to the number of CPU cores available in the system, and
# offers the best performance. Don't set it higher than the number of CPU
# cores if changing this parameter.

# The maximum number of connections for Nginx is calculated by:
# max_clients = worker_processes * worker_connections
worker_processes 2;

# Maximum open file descriptors per process;
# should be > worker_connections.
worker_rlimit_nofile 8192;

# Default error log file
# (this is only used when you don't override error_log on a server{} level)
error_log /var/log/nginx/error.log warn;
pid /run/nginx.pid;

# Don't run Nginx as a daemon.  This lets the docker host monitor the process.
daemon off;

events {
    # Number of simultaneous connections that can be opened by a worker.
    worker_connections 8000;

    # Accept as many connections as possible.
    multi_accept on;
}

http {

    # Hide Nginx version information.
    server_tokens off;

    # Define the MIME types for files.
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Format to use in log files
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';

    # Default log file
    # (this is only used when you don't override access_log on a server{} level)
    access_log /var/log/nginx/access.log main;

    # How long to allow each connection to stay idle; longer values are better
    # for each individual client, particularly for SSL, but means that worker
    # connections are tied up longer. (Default: 65)
    keepalive_timeout 20;

    client_header_timeout 20;
    client_body_timeout 20;
    reset_timedout_connection on;
    send_timeout 20;

    # Speed up file transfers by using sendfile() to copy directly
    # between descriptors rather than using read()/write().
    sendfile        on;

    # Tell Nginx not to send out partial frames; this increases throughput
    # since TCP frames are filled up before being sent out. (adds TCP_CORK)
    tcp_nopush      on;

    # Tell Nginx to enable the Nagle buffering algorithm for TCP packets, which
    # collates several smaller packets together into one larger packet, thus saving
    # bandwidth at the cost of a nearly imperceptible increase to latency. (removes TCP_NODELAY)
    tcp_nodelay     off;

    # Sets the maximum size of the types hash tables.
    # http://nginx.org/en/docs/hash.html
    types_hash_max_size 2048;

    # Set the bucket size for the server names hash tables.
    server_names_hash_bucket_size 64;

    # Don't use the server_name set in Nginx, instead use the "Host" field from the request.
    server_name_in_redirect off;

    # Compression

    # Enable Gzip compressed.
    gzip on;

    # Enable compression both for HTTP/1.0 and HTTP/1.1 (required for CloudFront).
    gzip_http_version  1.0;

    # Compression level (1-9).
    # 5 is a perfect compromise between size and cpu usage, offering about
    # 75% reduction for most ascii files (almost identical to level 9).
    gzip_comp_level    5;

    # Don't compress anything that's already small and unlikely to shrink much
    # if at all (the default is 20 bytes, which is bad as that usually leads to
    # larger files after gzipping).
    gzip_min_length    256;

    # Compress data even for clients that are connecting to us via proxies,
    # identified by the "Via" header (required for CloudFront).
    gzip_proxied       any;

    # Tell proxies to cache both the gzipped and regular version of a resource
    # whenever the client's Accept-Encoding capabilities header varies;
    # Avoids the issue where a non-gzip capable client (which is extremely rare
    # today) would display gibberish if their proxy gave them the gzipped version.
    gzip_vary          on;

    # Compress all output labeled with one of the following MIME-types.
    gzip_types
        application/atom+xml
        application/javascript
        application/json
        application/rss+xml
        application/vnd.ms-fontobject
        application/x-font-ttf
        application/x-web-app-manifest+json
        application/xhtml+xml
        application/xml
        font/opentype
        image/svg+xml
        image/x-icon
        text/css
        text/plain
        text/x-component;
    # text/html is always compressed by HttpGzipModule


    # This should be turned on if you are going to have pre-compressed copies (.gz) of
    # static files available. If not it should be left off as it will cause extra I/O
    # for the check. It is best if you enable this in a location{} block for
    # a specific directory, or on an individual server{} level.
    # gzip_static on;

    # Protect against the BEAST attack by preferring RC4-SHA when using SSLv3 and TLS protocols.
    # Note that TLSv1.1 and TLSv1.2 are immune to the beast attack but only work with OpenSSL v1.0.1 and higher and has limited client support.
    ssl_protocols              SSLv3 TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Optimize SSL by caching session parameters for 10 minutes. This cuts down on the number of expensive SSL handshakes.
    # The handshake is the most CPU-intensive operation, and by default it is re-negotiated on every new/parallel connection.
    # By enabling a cache (of type "shared between all Nginx workers"), we tell the client to re-use the already negotiated state.
    # Further optimization can be achieved by raising keepalive_timeout, but that shouldn't be done unless you serve primarily HTTPS.
    ssl_session_cache    shared:SSL:10m; # a 1mb cache can hold about 4000 sessions, so we can hold 40000 sessions
    ssl_session_timeout  10m;

    # This default SSL certificate will be served whenever the client lacks support for SNI (Server Name Indication).
    # Make it a symlink to the most important certificate you have, so that users of IE 8 and below on WinXP can see your main site without SSL errors.
    #ssl_certificate      /etc/nginx/default_ssl.crt;
    #ssl_certificate_key  /etc/nginx/default_ssl.key;

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}